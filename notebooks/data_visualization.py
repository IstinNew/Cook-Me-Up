# -*- coding: utf-8 -*-
"""data_visualization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18Ee5QhDC2V_8inPP8yID4-DRdIEvhyej

#### **Cook-Me-Up Project: Simplifying Culinary Delights with Data**
**Data Exploration Extension File**

**Visualizations using Seaborn and Machine Learning**

    Explore relationships between multiple features.

    Identify patterns and anomalies using statistical tests.

    Encode categorical variables for machine learning models.

    Use clustering techniques to group similar recipes.

    Perform predictive modeling to understand how different features influence a specific outcome (e.g., cooking time).

#### **Global Configuration**
"""

import pandas as pd                                             # Importing the required libraries
import numpy as np                                              # Importing the required libraries
import matplotlib.pyplot as plt                                 # Importing the required libraries
import seaborn as sns                                           # Importing the required libraries
import scipy.stats as stats                                     # Importing the required libraries
from sklearn.cluster import KMeans                              # Importing the KMeans module from sklearn.cluster
from sklearn.preprocessing import LabelEncoder, StandardScaler  # Importing the LabelEncoder and StandardScaler module from sklearn.preprocessing
from pydrive.auth import GoogleAuth                             # Importing the google drive authentication module(when needed)
from pydrive.drive import GoogleDrive                           # Importing the google drive module(when needed)

import warnings
warnings.filterwarnings('ignore')

"""* Import necessary libraries
* Load the sorted dataset from Google Drive
"""

# Read the sorted data file from Google Drive
url_sorted = "https://drive.google.com/file/d/191wkXiU-T5YEkYigmMHImlkh9kQDkbPy/view?usp=sharing"
path = "https://drive.google.com/uc?export=download&id=" + url_sorted.split("/")[-2]
df_sorted = pd.read_csv(path)

print("Sorted data loaded successfully!")
print(df_sorted.head())

# Print unique values
print(df_sorted['flavor_profile'].unique())
print(df_sorted['state'].unique())
print(df_sorted['region'].unique())
print(df_sorted['cook_time'].unique())
print(df_sorted['prep_time'].unique())
print(df_sorted['course'].unique())
print(df_sorted['diet'].unique())

"""### EDA Visualizations
#### 1. Creating Empty Lists to be Filled Later on with region-wise ingredients
#### 2. Creating Empty Lists to perform frequency count of each ingredient that is used
"""

# Creating empty lists for all regions which will be later filled with ingredients used in that particular region
InEast = []
InWest = []
InNorth = []
InOthers = []
InNorthEast = []
InSouth = []
InCentral = []

# Filling the lists
for row in range(len(df_sorted)):
    if df_sorted['region'][row] == 'East':
        InEast.extend(df_sorted['ingredients'][row].split(', '))
    elif df_sorted['region'][row] == 'West':
        InWest.extend(df_sorted['ingredients'][row].split(', '))
    elif df_sorted['region'][row] == 'North':
        InNorth.extend(df_sorted['ingredients'][row].split(', '))
    elif df_sorted['region'][row] == 'North East':
        InNorthEast.extend(df_sorted['ingredients'][row].split(', '))
    elif df_sorted['region'][row] == 'South':
        InSouth.extend(df_sorted['ingredients'][row].split(', '))
    elif df_sorted['region'][row] == 'Central':
        InCentral.extend(df_sorted['ingredients'][row].split(', '))
    else:
        InOthers.extend(df_sorted['ingredients'][row].split(', '))

# Series which include each unique ingredient value
all_ingredient = pd.Series(InEast + InWest + InNorth + InOthers + InNorthEast + InSouth + InCentral).unique()

# Creating empty lists that will store the number of times each ingredient is used
InEastCount = []
InWestCount = []
InNorthCount = []
InOthersCount = []
InNorthECount = []
InSouthCount = []
InCentralCount = []

# Filling the lists
for ingredient in all_ingredient:
    InEastCount.append(InEast.count(ingredient))
    InWestCount.append(InWest.count(ingredient))
    InNorthCount.append(InNorth.count(ingredient))
    InOthersCount.append(InOthers.count(ingredient))
    InNorthECount.append(InNorthEast.count(ingredient))
    InSouthCount.append(InSouth.count(ingredient))
    InCentralCount.append(InCentral.count(ingredient))

# Creating the dataset with the values collected
ingredient_per_region = pd.DataFrame({'East': InEastCount, 'West': InWestCount, 'North': InNorthCount, 'Others': InOthersCount, 'North East': InNorthECount,
                                      'South': InSouthCount, 'Central': InCentralCount}, index=all_ingredient)

# Adding a column with the sum of all the other columns
ingredient_per_region['Sum'] = (ingredient_per_region['East'] + ingredient_per_region['West'] + ingredient_per_region['North'] +
                                ingredient_per_region['Others'] + ingredient_per_region['North East'] + ingredient_per_region['South'] +
                                ingredient_per_region['Central'])

"""### EDA Visualizations
#### 3. Heatmap of Ingredient Correlations Across Regions
#### 4. Pair Plot for Exploring Relationships
"""

# Heatmap of Ingredient Correlations Across Regions
plt.figure(figsize=(14, 10), dpi=100)
correlation_matrix = ingredient_per_region.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Heatmap of Ingredient Correlations Across Regions')
plt.show()

"""The created heatmap is to visualize the correlations between the frequency of different ingredients across various regions. This helps in understanding which ingredients are commonly used together in different regions.

1. **Zones (Central, South, North, Northeast, West, East, Others)**:
   - These are likely categorical labels representing different regions or zones in your dataset. Each zone is represented as a box in the heatmap.

2. **Values from 0.0 to 1.0**:
   - These values are typically normalized data points that fall within the range of 0.0 to 1.0. In the context of a heatmap, these values are used to determine the color intensity of each box. For example, a value closer to 1.0 might represent a higher intensity (darker color), while a value closer to 0.0 might represent a lower intensity (lighter color).

3. **Color Representation**:
   - The color of each box in the heatmap corresponds to the value it represents. This visual representation helps to quickly identify patterns, correlations, or anomalies in the data.
"""

# Pair Plot for Exploring Relationships
df_sorted['total_time'] = df_sorted['prep_time'] + df_sorted['cook_time']
df_sorted['num_ingredients'] = df_sorted['ingredients'].apply(lambda x: len(x.split(', ')))

# Selecting relevant columns for pair plot
pair_plot_data = df_sorted[['total_time', 'num_ingredients', 'flavor_profile', 'course', 'region']]

# Encoding categorical columns
label_encoder = LabelEncoder()
pair_plot_data['flavor_profile'] = label_encoder.fit_transform(pair_plot_data['flavor_profile'])
pair_plot_data['course'] = label_encoder.fit_transform(pair_plot_data['course'])
pair_plot_data['region'] = label_encoder.fit_transform(pair_plot_data['region'])

# Creating the pair plot
sns.pairplot(pair_plot_data, hue='region', palette='Set1', markers=["o", "s", "D", "P", "X", "^", "v", "<", ">"])
plt.title('Pair Plot for Exploring Relationships')
plt.show()

"""The resulting pair plot explores the relationships between features such as total time, number of ingredients, flavor profile, course, and region. This visualization helps in understanding how these features interact with each other.

A pair plot is a matrix of scatter plots that allows you to visualize the relationships between multiple features in a dataset. Each cell in the matrix represents a scatter plot of two features, with one feature on the X-axis and the other on the Y-axis. Here's how to read and interpret the pair plot:

1. **Axes**:
   - The X-axis and Y-axis of each scatter plot represent different features from dataset. For example, one scatter plot might have `total_time` on the X-axis and `num_ingredients` on the Y-axis.

2. **Features**:
   - The features mentioned (`total_time`, `num_ingredients`, `flavor_profile`, `course`, and `region`) will be plotted against each other in different combinations. Each feature will appear once on the X-axis and once on the Y-axis in different scatter plots.

3. **Legend**:
   - The legend indicates different categories or groups within data. For example, `region` might have values from 0 to 7, each represented by a different color or marker (e.g., squares, diamonds).

4. **Markers**:
   - Different shapes (e.g., squares, diamonds) represent different categories or groups within a feature. For example, different regions might be represented by different shapes.

5. **Distributions**:
   - The diagonal cells of the pair plot typically show the distribution of each feature. These might be histograms, rising and falling bell-shaped graphs (indicating normal distribution), or other types of plots that show how the values of a feature are distributed.

### EDA Visualizations
#### 5. Region-wise ingredients Count Frequency
"""

# Plotting the graph
plt.figure(figsize=(12, 16), dpi=100)

for n, region in enumerate(ingredient_per_region.columns[:-1]):  # Exclude the 'Sum' column
    ord = ingredient_per_region.sort_values([region], ascending=False)[0:15]
    plt.subplot(4, 2, n+1)
    sns.barplot(x=ord[region], y=ord.index, palette='Paired')
    plt.xlabel('Count')
    plt.ylabel('Ingredients')
    plt.title(f'{region} Ingredient Frequency')
    plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

ingredient_per_region.head()