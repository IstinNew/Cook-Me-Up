# -*- coding: utf-8 -*-
"""data_exploration.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Fr-KxQa60hVAbs1YvPnMndBJbiN7ovsF

#### **Cook-Me-Up Project: Simplifying Culinary Delights with Data**
**Data Exploration**

1. **Load the Cleaned Data**

    Read the cleaned_data.csv file into a pandas DataFrame.

2. **Final Data Checkpoints**

    Generate descriptive statistics.

3. **Exploratory Data Analysis (EDA) - Level 1**

    Visualize the distribution of key numerical features (e.g., cooking time, number of ingredients).

    Analyze categorical features by visualizing the frequency of different categories (e.g., diet type, course, region).

    Identify correlations between different features using a correlation matrix.

    Generate insights from the data to inform further analysis and feature engineering.

4. **Advanced Data Exploration - EDA Level 2**
   **Visualizations - Using Seaborn and Machine Learning(separate python file)**

    Explore relationships between multiple features.

    Identify patterns and anomalies using statistical tests.

    Encode categorical variables for machine learning models.

    Use clustering techniques to group similar recipes.

    Perform predictive modeling to understand how different features influence a specific outcome (e.g., cooking time).

#### **Global Configuration**
"""

import pandas as pd                                             # Importing the required libraries
import numpy as np                                              # Importing the required libraries
import matplotlib.pyplot as plt                                 # Importing the required libraries
import seaborn as sns                                           # Importing the required libraries
import scipy.stats as stats                                     # Importing the required libraries

from pydrive.auth import GoogleAuth                             # Importing the google drive authentication module(when needed)
from pydrive.drive import GoogleDrive                           # Importing the google drive module(when needed)

import warnings
warnings.filterwarnings('ignore')

"""* Import necessary libraries
* Load the dataset
* Analyze ingredients used per region
* Visualize ingredient frequency per region
* Analyze course distribution per region
* Analyze flavor profile distribution
* Visualize ingredient frequency per flavor profile
* Calculate total preparation and cooking time
* Identify fastest dishes per course
"""

# Read the cleaned data file on GDrive
url_cleaned = "https://drive.google.com/file/d/12BM2d2Yv53dvf2b83gGlmzbtCKBt2Q6n/view?usp=sharing"
path = "https://drive.google.com/uc?export=download&id="+url_cleaned.split("/")[-2]
data = pd.read_csv(path)
df=data.copy()

# Final Data Checkpoints
# Check uncheck comments as needed

# Check the data type of the columns
df.info()

# Check the shape of the data
# print(df_cleaned.shape)

# Check the first 5 rows of the data
print(df.head())

# Check the column names
# print(df.columns)

# Check the data types of the columns
# print(df.dtypes)

# Check the missing values
# print(df.isnull().sum())

# Check the unique values in each column
for column in df.columns:
    print(f"{column}: {df[column].unique()}")

# Check the summary statistics of the data
# print(df.describe())

# Check the distribution of the data
# df.hist(figsize=(10, 10))
# plt.show()

# Check the correlation between the columns
# print(df.corr())

# Check the outliers in the data
# sns.boxplot(data=df)
# plt.show()

# Check the relationship between the columns
# sns.pairplot(df)
# plt.show()

# Check the data for any patterns
# sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
# plt.show()

"""Final Step to prepare data for analysis:
* Flavour Profile: -1 state and region values, change tp 'others'
* Preparation & Cooking time: -1 values, change to 0
"""

# Create a sorted copy of the dataframe
df_sorted = df.copy()

# Replace -1 values with 'Others'
df_sorted['flavor_profile'] = df_sorted['flavor_profile'].replace('-1', 'Others')
df_sorted['state'] = df_sorted['state'].replace('-1', 'Others')
df_sorted['region'] = df_sorted['region'].replace('-1', 'Others')
df_sorted['cook_time'] = df_sorted['cook_time'].replace(-1, 0)
df_sorted['prep_time'] = df_sorted['prep_time'].replace(-1,0)

# Print unique values
print(df_sorted['flavor_profile'].unique())
print(df_sorted['state'].unique())
print(df_sorted['region'].unique())
print(df_sorted['cook_time'].unique())
print(df_sorted['prep_time'].unique())
print(df_sorted['course'].unique())
print(df_sorted['diet'].unique())

"""sorted_file_path specifies the location and name of the CSV file where the sorted DataFrame will be saved.

df_sorted.to_csv(sorted_file_path, index=False) saves the DataFrame to the specified file path without writing row indices.

print(f"Sorted data saved to {sorted_file_path}") outputs a confirmation message indicating where the file has been saved.
"""

# Save the sorted dataframe to a CSV file
sorted_file_path = r'D:/WBS Coding/Bootcamp/Project Works/Final Project/Data/sorted_data.csv'
df_sorted.to_csv(sorted_file_path, index=False)

print(f"Sorted data saved to {sorted_file_path}")

# Read the sorted data file from Google Drive
url_sorted = "https://drive.google.com/file/d/191wkXiU-T5YEkYigmMHImlkh9kQDkbPy/view?usp=sharing"
path = "https://drive.google.com/uc?export=download&id=" + url_sorted.split("/")[-2]
df_sorted = pd.read_csv(path)

print("Sorted data loaded successfully!")
print(df_sorted.head())

"""### EDA Level-1 Explorations
#### 1. Analyze ingredients used per region
"""

ingredients_per_region = df_sorted.groupby('region')['ingredients'].apply(lambda x: ' '.join(x)).reset_index()

# Ingredient frequency per region
for region in ingredients_per_region['region'].unique():
        region_data = ingredients_per_region[ingredients_per_region['region'] == region]
        ingredients = ' '.join(region_data['ingredients']).split()
        ingredients_freq = pd.Series(ingredients).value_counts()

        plt.figure(figsize=(10, 6))
        ingredients_freq[:20].plot(kind='bar')
        plt.title(f'Ingredient Frequency in {region}')
        plt.xlabel('Ingredient')
        plt.ylabel('Frequency')
        plt.show()

"""### EDA Level-1 Explorations
#### 2. Analyze course distribution per region
"""

course_distribution = df_sorted.groupby('region')['course'].value_counts().unstack().fillna(0)

plt.figure(figsize=(12, 8))
sns.heatmap(course_distribution, annot=True, cmap='coolwarm')
plt.title('Course Distribution per Region')
plt.xlabel('Course')
plt.ylabel('Region')
plt.show()

"""### EDA Level-1 Explorations
#### 3. Analyze Flavour Profile
"""

flavor_profile_distribution = df_sorted['flavor_profile'].value_counts()

plt.figure(figsize=(10, 6))
flavor_profile_distribution.plot(kind='bar')
plt.title('Flavor Profile Distribution')
plt.xlabel('Flavor Profile')
plt.ylabel('Frequency')
plt.show()

ingredients_per_flavor = df_sorted.groupby('flavor_profile')['ingredients'].apply(lambda x: ' '.join(x)).reset_index()

for flavor in ingredients_per_flavor['flavor_profile'].unique():
    flavor_data = ingredients_per_flavor[ingredients_per_flavor['flavor_profile'] == flavor]
    ingredients = ' '.join(flavor_data['ingredients']).split()
    ingredients_freq = pd.Series(ingredients).value_counts()

    plt.figure(figsize=(10, 6))
    ingredients_freq[:20].plot(kind='bar')
    plt.title(f'Ingredient Frequency in {flavor} Flavor Profile')
    plt.xlabel('Ingredient')
    plt.ylabel('Frequency')
    plt.show()

"""### EDA Level-1 Explorations
#### 4. Total Preparation & Cooking Times
"""

df_sorted['total_time'] = df_sorted['prep_time'] + df_sorted['cook_time']

plt.figure(figsize=(10, 6))
sns.histplot(df_sorted['total_time'], bins=30, kde=True)
plt.title('Distribution of Total Preparation and Cooking Time')
plt.xlabel('Total Time (minutes)')
plt.ylabel('Frequency')
plt.show()

"""### EDA Level-1 Explorations
#### 5. Fastest Dish per Course
"""

fastest_dishes_per_course = df_sorted.loc[df_sorted.groupby('course')['total_time'].idxmin()]

print("\nFastest Dishes Per Course:")
print(fastest_dishes_per_course[['name', 'course', 'total_time']])